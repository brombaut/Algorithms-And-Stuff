### Logistic Regression
# Fit a logistic regression model in order to predict Direction using Lag1 through Lag5 and volume
glm.fits = glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume, data=Smarket, family=binomial)
summary(glm.fits)
# Use coef() in order to access just the coefficients for this fitted model.
coef(glm.fits)
summary(glm.fits)$coef
summary(glm.fits)$coef[,4]
detach(Smarket)
detach(Smarket)
detach(Smarket)
detach(Smarket)
rm(list=ls())
library(ISLR)
### The Stock Market Data
names(Smarket)
dim(Smarket)
summary(Smarket)
pairs(Smarket)
# Produce a matrix that contains all of the pairwise correlations among the predictors in a data set
cor(Smarket [,-9])
# Only substantial correlation is between Year and Volume.
attach(Smarket)
plot(Volume)
### Logistic Regression
# Fit a logistic regression model in order to predict Direction using Lag1 through Lag5 and volume
glm.fits = glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume, data=Smarket, family=binomial)
summary(glm.fits)
# Use coef() in order to access just the coefficients for this fitted model.
coef(glm.fits)
summary(glm.fits)$coef
summary(glm.fits)$coef[,4]
# Use predict() function to predict the probability that the market will go up, given values
# of the predictors. The type="response" options tells R to output probabilities of the form P(Y=1|X),
# as opposed to other information such as the logit.
glm.probs = predict(glm.fits, type="response")
glm.probs[1:10]
# We know that these values correspond to the probability of the market going up, rather than down,
# because the contrasts() function indicates that R has created a dummy variable with a 1 for Up.
contrasts(Direction)
# Create a vector of class predictions based on whether the predicted probability of a market
# increase is greater than or less than 0.5
glm.pred = rep("Down", 1250)
glm.pred[glm.probs > 0.5] = "Up"
# How many observations were correctly or incorrectly classified
table(glm.pred, Direction)
(507+145)/1250
mean(glm.pred == Direction)
# Create avector corresponding to the obervations from 2001 to 2004.
# We will then use this vector to vteaye a held out data set of observations from 2005.
train=(Year<2005)
Smarket.2005=Smarket[!train,]
dim(Smarket.2005)
Direction.2005=Direction[!train]
# Now fit a logistic regression model using only the subset of the obervations that correspond to
# dates before 2005. Then obtain predicted probabilities of the stock market going up for each of the
# days in our test set - that is, for the days in 2005.
glm.fits=glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume, data=Smarket, family=binomial, subset=train)
glm.probs=predict(glm.fits, Smarket.2005, type="response")
# Note that we have trained and tested our model on two completly separate data sets: training was
# performed using only the dates before 2005, and testing was performed using only the dates in 2005.
# Finally, we compute the predictions for 2005 and compare them to the actual movements of the market
# over that time period.
glm.pred=rep("Down", 252)
glm.pred[glm.probs > 0.5] = "Up"
table(glm.pred, Direction.2005)
mean(glm.pred == Direction.2005)
mean(glm.pred != Direction.2005)
# A dissapointing error rate of 52%. What if we try and remove the predictors that have the highest p-values?
glm.fits=glm(Direction~Lag1+Lag2, data=Smarket, family=binomial, subset=train)
glm.probs=predict(glm.fits, Smarket.2005, type="response")
glm.pred=rep("Down", 252)
glm.pred[glm.probs > 0.5] = "Up"
table(glm.pred, Direction.2005)
mean(glm.pred == Direction.2005)
106/(106+76)
### Linear Discriminant Analysis
# Perform LDA on the Smarket data.
library(MASS)
lda.fit=lda(Direction~Lag1+Lag2, data=Smarket, subset=train)
lda.fit
plot(lda.fit)
lda.pred = predict(lda.fit, Smarket.2005)
names(lda.pred)
lda.class = lda.pred$class
table(lda.class, Direction.2005)
mean(lda.class==Direction.2005)
sum(lda.pred$posterior[,1] >= 0.5)
sum(lda.pred$posterior[,1] < 0.5)
lda.pred$posterior[1:20,1]
lda.class[1:20]
sum(lda.pred$posterior[,1] > 0.9)
### Quadratic Discriminant Analysis
# Fit a QDA model to the Smarket data.
qda.fit=qda(Direction~Lag1+Lag2, data=Smarket, subset=train)
qda.fit
# The output contains the group means. But it does not contain the coefficients of the linear
# discriminants, because the QDA classifier involves a quadratic, rather than linear, function of
# the predictos. The predict() function works in exactly the same fashion as LDA.
qda.class=predict(qda.fit, Smarket.2005)$class
table(qda.class, Direction.2005)
mean(qda.class == Direction.2005)
### K-Nearest Neighbors
# We need some specific inputs for knn() function.
library(class)
train.X=cbind(Lag1, Lag2)[train,]
test.X=cbind(Lag1, Lag2)[!train,]
train.Direction=Direction[train]
# We must set a seed to ensure reproducibility of results, since if if several observations are tied
# as nearest neighbors, then R will randomly break the tie.
set.seed(1)
knn.pred=knn(train.X, test.X, train.Direction, k=1)
table(knn.pred, Direction.2005)
(83+43)/252
# The results using K=1 are not very good, since only 50% of the observations are correctly predicted.
# Of course, it may be that K=1 results in an overly flexible fit to the data. Repeat with K=3.
knn.pred=knn(train.X, test.X, train.Direction, k=3)
table(knn.pred, Direction.2005)
mean(knn.pred == Direction.2005)
### An Application to Caravan Insurance Data
# Apply the KNN approach to the Caravan data set.
dim(Caravan)
attach(Caravan)
summary(Purchase)
348/5474
# Because the KNN classifier predicts the class of a given test observation by identifying the obervations
# that are nearest to it, the scale of the variables atters. Any variables that are on a huge scale will
# have a much larger effect on the distance between the observations.
# A good way to handle this problem is to standardize the data so that all variables are given
# a mean of zero and a standard deviation of one. Then all variables will be one a comparable scale.
# The scale() function does just this. In standardizing the data, we exclude column 86, because
# this is the qualitative Purchase variable.
standardized.X = scale(Caravan[, -86])
var(Caravan-,1)
var(Caravan[,1])
var(Caravan[,2])
var(standardized.X[,1])
var(standardized.X[,2])
# Now every column of standardized.X has a standard deviation of one and a mean of zero.
# We now split the observations into a test set, containing the first 1000 obervations,
# and a training set, containing the remaining observations.
# We fit the KNN model on the training data using K=1, and evaluate its performance on the test data.
test=1:1---
# Now every column of standardized.X has a standard deviation of one and a mean of zero.
# We now split the observations into a test set, containing the first 1000 obervations,
# and a training set, containing the remaining observations.
# We fit the KNN model on the training data using K=1, and evaluate its performance on the test data.
test=1:1000
# Now every column of standardized.X has a standard deviation of one and a mean of zero.
# We now split the observations into a test set, containing the first 1000 obervations,
# and a training set, containing the remaining observations.
# We fit the KNN model on the training data using K=1, and evaluate its performance on the test data.
test=1:1000
train.X = standardized.X[-test,]
test.X = standardized.X[test,]
train.Y = Purchase[-test]
test.Y = Purchase[test]
set.seed(1)
knn.pred = knn(train.X, test.X, train.Y, k=1)
mean(test.Y != knn.pred)
mean(test.Y != "No")
# however, since only 6% of customers purchased insurance, we could get the error rate down to 6% by
# always predicting No regardless of the values of the predictions.
# Suppose that there is some non-trivial cost to trying to sell insurance to a given individual. If
# the company tries to sell insurance to a random selection of customers, the the success rate will only
# be 6%, which may be far to low given the costs involved. Instead, the company would like to try
# to sell insurance only to customers who are likely to buy it. So the overall error rate is not of interest.
# Instead, the fraction of individuals that are correctly predicted to buy insurance is of interest.
# It turns out that KNN wutg K=1 does far better than random guessing among the customers that are
# predicted to buy insurance. Among 77 such customers, 9, or 11.7%, actually do purchase insurance.
# This is double the rate that one would obtain from random guessing.
table(knn.pred, test.Y)
9/(68+9)
# Using K=3, the success rate increases to 19%, and with K=5 the rate is 26.7%. This is over four
# times the rate that results from random guessing. It appears that KNN is finding some real
# patterns in a difficult data set.
knn.pred = knn(train.X, test.X, train.Y, k=3)
table(knn.pred, test.Y)
5/26
knn.pred = knn(train.X, test.X, train.Y, k=5)
table(knn.pred, test.Y)
4/15
# As a comparison, we can also fit a logistic regression model to the data. If we use 0.5 as the
# predicted probability cut-off for the cliassifier, then we have a problem: only seven of the test
# observations are predicted to purchase insurance. Even worse, we are wrong about all of these!
# However, we are not required to use a cut-off of 0.5. If we instead predict a purchase any time
# the predicted probability of purchase exceeds 0.25, we get much better results: we predict
# that 33 people will purchase insurance, and we are correct for 33% of these people. This
# is over five times better than random guessing.
glm.fits=glm(Purchase~., data=Caravam, family=binomial, subset=-test)
# As a comparison, we can also fit a logistic regression model to the data. If we use 0.5 as the
# predicted probability cut-off for the cliassifier, then we have a problem: only seven of the test
# observations are predicted to purchase insurance. Even worse, we are wrong about all of these!
# However, we are not required to use a cut-off of 0.5. If we instead predict a purchase any time
# the predicted probability of purchase exceeds 0.25, we get much better results: we predict
# that 33 people will purchase insurance, and we are correct for 33% of these people. This
# is over five times better than random guessing.
glm.fits=glm(Purchase~., data=Caravan, family=binomial, subset=-test)
glm.probs = predict(glm.fits, Caravan[test,], type="response")
glm.pred=rep("No", 1000)
glm.pred[glm.probs > 0.5] = "Yes"
table(glm.pred, test.Y)
glm.pred=rep("No", 1000)
glm.pred[glm.probs > 0.25] = "Yes"
table(glm.pred, test.Y)
11/(22+11)
library(ISLR)
library(MASS)
library(ISLR)
rm(list=ls())
library(ISLR)
library(MASS)
## 10
# a) Produce some numberical and graphical summaries of the Weekly data.
# Do there appear to be any patterns?
summary(Weekly)
?Weekly
pairs(Weekly)
cor(Weekly[, -9])
# Year and volumen appear to be related. Nothing else stands out
# b) Use the full data set to perform a logistic regression with Direstion as the response
# and the five lag variables plus Volume as predictos. Use the summary function to print the results.
# Do any of the predictors appear to be statistically significant? If so, which ones?
attach(Weekly)
rm(list=ls())
library(ISLR)
## 10
# a) Produce some numberical and graphical summaries of the Weekly data.
# Do there appear to be any patterns?
summary(Weekly)
pairs(Weekly)
cor(Weekly[, -9])
# Year and volumen appear to be related. Nothing else stands out
# b) Use the full data set to perform a logistic regression with Direstion as the response
# and the five lag variables plus Volume as predictos. Use the summary function to print the results.
# Do any of the predictors appear to be statistically significant? If so, which ones?
attach(Weekly)
detach(Weekly)
detach(Weekly)
detach(Weekly)
detach(Smarket)
# Year and volumen appear to be related. Nothing else stands out
# b) Use the full data set to perform a logistic regression with Direstion as the response
# and the five lag variables plus Volume as predictos. Use the summary function to print the results.
# Do any of the predictors appear to be statistically significant? If so, which ones?
attach(Weekly)
glm.fit = glm(Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume, data=Weekly, family=binomial)
summary(glm.fit)
# Lag2 has a p-value of around 0.03
# c) Compute the confusion matrix and overall fraction of correct predictions. Explain what the confusion
# matrix is telling you about the types of mistakes made by logistic regression.
glm.probs = predict(glm.fit, type = "response")
glm.probs
glm.pred = rep("Down", length(glm.probs))
glm.pred[glm.probs > 0.5] = "Up"
table(glm.pred, Direction)
# Percentage of correct predictions: (54+557)/(54+557+48+430) = 56.1%.
# Weeks the market goes up the logistic regression is right most of the time, 557/(557+48) = 92.1%.
# Weeks the market goes up the logistic regression is wrong most of the time 54/(430+54) = 11.2%.
# d) Now fit the logistic regression model using a training data period from 1990 to 2008,
# with Lag2 as the only predictor. Compute the confusion matrix and the overall fraction of correct
# predictions for the held out data (i.e. the data from 2009 and 2010)
train = (Year < 2009)
# Percentage of correct predictions: (54+557)/(54+557+48+430) = 56.1%.
# Weeks the market goes up the logistic regression is right most of the time, 557/(557+48) = 92.1%.
# Weeks the market goes up the logistic regression is wrong most of the time 54/(430+54) = 11.2%.
# d) Now fit the logistic regression model using a training data period from 1990 to 2008,
# with Lag2 as the only predictor. Compute the confusion matrix and the overall fraction of correct
# predictions for the held out data (i.e. the data from 2009 and 2010)
train = (Year < 2009)
Weekly.1990 = Weekly[!train, ]
Weekly.test = Weekly[!train, ]
Weekly.test = Weekly[!train, ]
glm.fit = glm(Direction ~ Lag2, data = Weekly, family = binomial, subset = train)
glm.probs = predict(glm.fit, Weekly.test, type = "response")
glm.pred = rep("Down", length(glm.probs))
glm.pred[glm.probs > 0.5] = "Up"
Direction.test = Direction[!train]
table(glm.pred, Direction.test)
mean(glm.pred == Direction.test)
lda.fit = lda(Direction ~ Lag2, data = Weekly, subset = train)
# e) Repeat (d) using LDA.
library(MASS)
lda.fit = lda(Direction ~ Lag2, data = Weekly, subset = train)
lda.pred = predict(lda.fit, Weekly.test)
table(lda.pred$class, Direction.test)
mean(lda.pred$class == Direction.test)
# f) Repeat (d) using QDA.
qda.fit = qda(Direction ~ Lag2, data = Weekly, subset = train)
qda.class = predict(qda.fit, Weekly.test)$class
table(qda.class, Direction.test)
mean(qda.class == Direction.0910)
mean(qda.class == Direction.test)
# A correctness of 58.7% even though it picked Up the whole time!
# g) Repeat (d) using KNN with K=1
library(class)
train.X = as.matrix(Lag2[train])
test.X = as.matrix(Lag2[!train])
train.Direction = Direction[train]
set.seed(1)
knn.pred = knn(train.X, test.X, train.Direction, k = 1)
table(knn.pred, Direction.test)
mean(knn.pred == Direction.0910)
mean(knn.pred == Direction.test)
# h) Which of these methods appears to provide the best results on this data?
# Logistic regression and LDA methods provide similar test error rates.
# i) Experiment with different combinations of predictors, including possible transformations
# and interactions, for each of the methods. Report the variables, method, and associated
# confusion matrix that appears to provide the best results on the held out data.
# Note that you should also experiment with values for K in the KNN classifier.
#
# Logistic regression with Lag2:Lag1
glm.fit = glm(Direction ~ Lag2:Lag1, data = Weekly, family = binomial, subset = train)
glm.probs = predict(glm.fit, Weekly.test, type = "response")
glm.pred = rep("Down", length(glm.probs))
glm.pred[glm.probs > 0.5] = "Up"
Direction.test = Direction[!train]
table(glm.pred, Direction.test)
mean(glm.pred == Direction.test)
#
# LDA with Lag2 interaction with Lag1
lda.fit = lda(Direction ~ Lag2:Lag1, data = Weekly, subset = train)
lda.pred = predict(lda.fit, Weekly.test)
mean(lda.pred$class == Direction.test)
#
# QDA with sqrt(abs(Lag2))
qda.fit = qda(Direction ~ Lag2 + sqrt(abs(Lag2)), data = Weekly, subset = train)
qda.class = predict(qda.fit, Weekly.test)$class
table(qda.class, Direction.test)
table(qda.class, Direction.test)
mean(qda.class == Direction.test)
#
# KNN k =10
knn.pred = knn(train.X, test.X, train.Direction, k = 10)
table(knn.pred, Direction.test)
mean(knn.pred == Direction.test)
#
# KNN k = 100
knn.pred = knn(train.X, test.X, train.Direction, k = 100)
table(knn.pred, Direction.test)
mean(knn.pred == Direction.test)
## 11
# In this problem, you will develop a model to predict whether a given car gets high
# or low gas mileage based on the Auto data set.
library(ISLR)
summary(Auto)
# a) Create a binary variable, mpg01, that contains a 1 if mpg contains a value above
# its median, and a 0 if mpg contains a value below its median. You can compute the
# median using the median() function. Note you may find it helpful to use the data.drame()
# function to create a single data set containing both mpg01 and the other Auto variables
attach(Auto)
mpg01 = rep(0, length(mpg))
mpg01[mpg > median(mpg)] = 1
Auto = data.frame(Auto, mpg01)
# b) Explore the data graphically in order to investigate the association between mpg01
# and the other features. Which of the other features seem most likely to be useful in
# predicting mpg01? Scatterplots and boxplots may be useful tools to answer this question.
# Describe your findings.
cor(Auto[, -9])
# b) Explore the data graphically in order to investigate the association between mpg01
# and the other features. Which of the other features seem most likely to be useful in
# predicting mpg01? Scatterplots and boxplots may be useful tools to answer this question.
# Describe your findings.
cor(Auto[, -9])
# b) Explore the data graphically in order to investigate the association between mpg01
# and the other features. Which of the other features seem most likely to be useful in
# predicting mpg01? Scatterplots and boxplots may be useful tools to answer this question.
# Describe your findings.
cor(Auto[, -9])
pairs(Auto)  # doesn't work well since mpg01 is 0 or 1
pairs(Auto)  # doesn't work well since mpg01 is 0 or 1
# Anti-correlated with cylinders, weight, displacement, horsepower. (mpg, of course)
# c) Split the data into a training set and a test set.
train = (year%%2 == 0)  # if the year is even
test = !train
Auto.train = Auto[train, ]
Auto.test = Auto[test, ]
mpg01.test = mpg01[test]
# d) Perform LDA on the training data in order to predict mpg01 using the variables that seemed
# most associated with mpg01 in (b). What is the test error of the model obtained?
# LDA
library(MASS)
lda.fit = lda(mpg01 ~ cylinders + weight + displacement + horsepower, data = Auto, subset = train)
lda.pred = predict(lda.fit, Auto.test)
mean(lda.pred$class != mpg01.test)
# 12.6% test error rate.
# e) Perform QDA on the training data in order to predict mpg01 using the variables that seemed
# most associated with mpg01 in (b). What is the test error of the model obtained?
# QDA
qda.fit = qda(mpg01 ~ cylinders + weight + displacement + horsepower, data = Auto, subset = train)
qda.pred = predict(qda.fit, Auto.test)
mean(qda.pred$class != mpg01.test)
# 13.2% test error rate.
# f) Perform logistic regression on the training data in order to predict mpg01 using the
# variables that seemed most associated with mpg01 in (b). What is the test error of
# the model obtained?
# Logistic regression
glm.fit = glm(mpg01 ~ cylinders + weight + displacement + horsepower, data=Auto, family=binomial, subset=train)
glm.probs = predict(glm.fit, Auto.test, type = "response")
glm.pred = rep(0, length(glm.probs))
glm.pred[glm.probs > 0.5] = 1
mean(glm.pred != mpg01.test)
# 12.1% test error rate.
# f) Perform KNN on the training data in order to predict mpg01 using the
# variables that seemed most associated with mpg01 in (b). What is the test error of
# the model obtained? Which value of K seems to perform the best on this data set?
library(class)
train.X = cbind(cylinders, weight, displacement, horsepower)[train, ]
test.X = cbind(cylinders, weight, displacement, horsepower)[test, ]
train.mpg01 = mpg01[train]
set.seed(1)
# KNN(k=1)
knn.pred = knn(train.X, test.X, train.mpg01, k = 1)
mean(knn.pred != mpg01.test)
# 15.4% test error rate
# KNN(k=10)
knn.pred = knn(train.X, test.X, train.mpg01, k = 10)
mean(knn.pred != mpg01.test)
# 16.5 test error rate
# KNN(k=100)
knn.pred = knn(train.X, test.X, train.mpg01, k = 100)
mean(knn.pred != mpg01.test)
## 12
# a) Write a function, Power(), that prints out the result of raising 2 to the 3rd power.
Power = function() {
print(2^3)
}
Power()
# b) Create a new function, Power2(), that allows you to pass any two numbers, x and a,
# and prints out the value of x^a.
Power2 = function(x, a) {
print(x^a)
}
Power2(4, 3)
# c) Using Power2() function, compute 10^3, 8^17, 131^3.
Power2(10, 3)
Power2(8, 17)
Power2(131, 3)
# d) Now create a new function, Power3(), that actually returns the result x^a as an R object.
Power3 = function(x, a) {
return(x^a)
}
x = Power3(3, 3)
x
# e) Now using Power3() function, create a plot f(x)=x^2.
# The x-axis should display a range of integers from 1 to 10, and the y-axis should display x^2.
# Label the axes appropriately, and use an appropriate title for the figure. Consider displaying
# either the x-axis, the y-axis, or both on the log-scale.
x = 1:10
plot(x, Power3(x, 2), log="xy", ylab="Log of y = x^2", xlab="Log of x", main="Log of x^2 versus Log of x")
# f) Create a function, PlotPower(), that allows you to create a plot of x against x^a for a
# fixed a and for a range of values of x. For instance, if you call PlotPower(1:10,3) then
# a plot should be created with an x-axis taking on values 1,2,...,10, and a y-axis on
# values 1^3, 2^3, ..., 10^3.
PlotPower = function(x, a) {
plot(x, Power3(x, a))
}
PlotPower(1:10,3)
## 13
# Using the Boston data set, fit classification models in norder to predict whether a given
# suburb has a crime rate above or below the median. Explore logistic regression, LDA, and KNN
# models using various subsets of the predictors. Describe your findings.
library(MASS)
summary(Boston)
attach(Boston)
View(Boston)
crime01 = rep(0, length(crim))
crime01[crim > median(crim)] = 1
Boston = data.frame(Boston, crime01)
train = 1:(dim(Boston)[1]/2)
test = (dim(Boston)[1]/2 + 1):dim(Boston)[1]
Boston.train = Boston[train,]
Boston.test = Boston[test, ]
crime01.test = crime01[test]
# logistic regression
glm.fit = glm(crime01 ~ . - crime01 - crim, data=Boston, family=binomial, subset=train)
glm.probs = predict(glm.fit, Boston.test, type="response")
glm.pred = rep(0, length(glm.probs))
glm.pred[glm.probs>0.5] = 1
mean(glm.pred != crime01.test)
# LDA
lda.fit = lda(crime01~.-crime01-crim, data=Boston, subset=train)
lda.pred = predict(lda.fit, Boston.test)
mean(lda.pred$class != crime01.test)
lda.fit = lda(crime01~.-crime01-crim-chas-tax, data=Boston, subset=train)
lda.pred = predict(lda.fit, Boston.test)
mean(lda.pred$class != crime01.test)
lda.fit = lda(crime01~.-crime01-crim-chas-tax-lstat-indus-age, data=Boston, subset=train)
lda.pred = predict(lda.fit, Boston.test)
mean(lda.pred$class != crime01.test)
# KNN
library(class)
train.X = cbind(zn, indus, chas, nox, rm, age, dis, rad, tax, ptratio, black, lstat, medv)[train, ]
test.X = cbind(zn, indus, chas, nox, rm, age, dis, rad, tax, ptratio, black, lstat, medv)[test, ]
train.crime01 = crime01[train]
set.seed(1)
# KNN(k=1)
knn.pred = knn(train.X, test.X, train.crime01, k = 1)
mean(knn.pred != crime01.test)
# KNN(k=10)
knn.pred = knn(train.X, test.X, train.crime01, k=10)
mean(knn.pred != crime01.test)
# KNN(k=100)
knn.pred = knn(train.X, test.X, train.crime01, k=100)
mean(knn.pred != crime01.test)
# KNN(k=10) with subset of variables
train.X = cbind(zn, nox, rm, dis, rad, ptratio, black, medv)[train, ]
test.X = cbind(zn, nox, rm, dis, rad, ptratio, black, medv)[test, ]
knn.pred = knn(train.X, test.X, train.crime01, k=10)
mean(knn.pred != crime01.test)
source('~/Dev/BEC/intro_to_statistical_learning/chpt4_classification/chpt4_classification_applied.R')
rm(list=ls())
